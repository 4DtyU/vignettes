---
title: "Packages and Vignettes"
output: github_document
author: "4DtyU"
---



```{r}
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 120),
  message = FALSE,
  warning = FALSE,
  echo = FALSE
)

extrafont::loadfonts(device="pdf")
extrafont::loadfonts(device="postscript")
library(ape)
library(chroma)
library(colormap)
library(corrplot)
library(cowplot)
library(ursa)
library(data.table)
library(datasets)
library(devtools)
library(downloader)
library(Ecdat)
library(embed)
library(epiR)
library(esquisse)
library(extrafont)
library(extrafontdb)
library(factoextra)
library(FactoMineR)
library(flexdashboard)
library(gapminder)
library(ggforce)
library(ggfortify)
library(ggplot2)
require(ggpointdensity)
library(ggpubr)
library(ggrepel)
library(ggsci)
#library(ggstatsplot)
library(ggvis)
library(ggh4x)
library(gmodels)
library(grid)
library(gridBase)
library(gridExtra)
library(gtable)
library(gtools)
library(GGally)
library(heatmaply)
library(hflights)
library(Hmisc)
library(here)
library(hms)
library(hrbrthemes)
library(jcolors)
library(knitr)
library(Lahman)
library(lattice)
library(lsr)
library(lubridate)
library(Matrix)
library(mlbench)
library(MASS)
library(nycflights13)
library(patchwork)
library(pheatmap)
library(plyr)
library(pzfx)
library(rafalib)
library(RColorBrewer)
library(readxl)
library(remotes)
library(reshape)
library(reshape2)
library(rio)
library(RPostgreSQL)
library(rlang)
library(rstatix)
library(rsvd)
library(scales)
library(sciplot)
library(scclusteval)
library(Seurat)
library(shiny)
library(stringr)
library(stringi)
library(skimr)
library(tidyr)
library(tidyselect)
library(tidyverse)
library(VennDiagram)
library(viridis)
library(writexl)
library(xlsx)
library(here)
library(RColorBrewer)
library(repurrrsive)
library(ggridges)
library(ggthemes)
library(tm)
library(SnowballC)
library(wordcloud)
library(e1071)
library(vroom)
library(tidylog)
library(janitor)
library(lubridate)
library(glue)
library(tsibble)
library(tidytext)
library(tidymodels)
library(rstatix)
theme_set(theme_bw(base_family = "Helvetica"))
theme_update(strip.background = element_rect(color="white", fill="#FFFFFF", size=0), 
          strip.text = element_text(colour = 'black', size = 12, face = "bold", hjust = 0),
          plot.tag = element_text(color = "ivory", hjust = 1, size = 8))
tag <- paste("Author: AKBird;", "Last edit:", Sys.Date())
tag

allDuplicated <- function(vec){
  front <- duplicated(vec)
  back <- duplicated(vec, fromLast = TRUE)
  all_dup <- front + back > 0
  return(all_dup)
}

toGreek <- function(x) {    #use library(stringi) ... 

   x <- gsub("alpha", "\u03b1", x)              # English to unicode
   x <- gsub("beta", "\u03b2", x)
   x <- gsub("gamma", "\u03b3", x)
   #x <- gsub("delta", "\u03b4", x)
   x <- gsub("epsilon", "\u03b5", x)
   x <- gsub("zeta", "\u03b6", x)
   x <- gsub("ug/mL", "\u03bcg/mL", x) 
   x <- gsub("uL", "\u03bcL", x)
}

toGreekLiteral <- function(x) {   

   x <- gsub("ug/mL", "μg/mL", x) 
   x <- gsub("alpha", "α", x)            
   x <- gsub("beta", "β", x)
   x <- gsub("gamma", "γ", x)
   #x <- gsub("delta", "δ", x)
   x <- gsub("epsilon", "ε", x)
   x <- gsub("zeta", "ζ", x)
   x <- gsub("ug/mL", "μg/mL", x) 
   x <- gsub("uL", "μL", x)

}

sem <- function(x) {sd(x)/sqrt(length(x))}

```


Xtra Funs

```{r}
allDuplicated <- function(vec){
  front <- duplicated(vec)
  back <- duplicated(vec, fromLast = TRUE)
  all_dup <- front + back > 0
  return(all_dup)
}


toGreek <- function(x) {    #use library(stringi) ... 

   x <- gsub("alpha", "\u03b1", x)              # English to unicode
   x <- gsub("beta", "\u03b2", x)
   x <- gsub("gamma", "\u03b3", x)
   x <- gsub("delta", "\u03b4", x)
   x <- gsub("epsilon", "\u03b5", x)
   x <- gsub("zeta", "\u03b6", x)
   x <- gsub("ug/mL", "\u03bcg/mL", x) 
   x <- gsub("uL", "\u03bcL", x)
}

toGreekLiteral <- function(x) {   

   x <- gsub("ug/mL", "μg/mL", x) 
   x <- gsub("alpha", "α", x)            
   x <- gsub("beta", "β", x)
   x <- gsub("gamma", "γ", x)
   x <- gsub("delta", "δ", x)
   x <- gsub("epsilon", "ε", x)
   x <- gsub("zeta", "ζ", x)
   x <- gsub("ug/mL", "μg/mL", x) 
   x <- gsub("uL", "μL", x)

}

tibble(x = c("ug/mL", "45ug/mL"),
       y = c("35 ug/mL", "2ug/mL"),
       z = c("delta_delta_ct", "zeta")) %>% map_dfr(., ~ toGreek2(.x)) %>% View

toEnglish <- function(x) {    #use library(stringi)
   x <- gsub("<U+03B1>", "alpha", x)  
   x <- gsub("<U+03B2>", "beta", x)
   x <- gsub("<U+03B3>", "gamma", x)
   x <- gsub("<U+03B4>", "delta", x)
   x <- gsub("<U+03B5>", "epsilon", x)
   x <- gsub("<U+03B6>", "zeta", x)
   cat(stri_unescape_unicode(gsub("<U\\+(....)>", "\\\\u\\1", x)))
}


```



```{r}

MyNewDir <- "C:/Users/kjwl754/Box Sync/Projects/MDSC Rhapsody/Analysis Active/jan2021 Analysis"

#set directory for rmd file
knitr::opts_knit$set(root.dir = MyNewDir)


#change here() directory
change_here <- function(new_path){
  new_root <- here:::.root_env
  
  new_root$f <- function(...){file.path(MyNewDir, ...)}
  
  assignInNamespace(".root_env", new_root, ns = "here")
}

change_here()
here()

```


Grab data off of github

```{r}
setwd("C:/Users/kjwl754/Desktop")
library(downloader)
url <- "https://raw.githubusercontent.com/4DtyU/tidy-text-mining/master/01-tidy-text.Rmd"
filename <- "01_tidy_text.Rmd"
if(!file.exists(filename)) download(url, destfile = filename)
```





                    
 # # # # # # # # #                                    # # # # # # # # # 
##################      >  Vignettes & Tools  <       ##################
 # # # # # # # # #                                    # # # # # # # # # 


Ctrl + f (search section)

[  Section 1  ] Cumulative Distribution, Percentiles, Intervals
[  Section 2  ] Graphpad Prism Export
[  Section 3  ] Import multiple files as separate data frames
[  Section 4  ] FACS
[  Section 5  ] Correlations
[  Section 6  ] ELISA
[  Section 7  ] Plotting
[  Section 8  ] Stats on plots!
[  Section 9  ] Median Normalization
[  Section 10 ] PURRR Examples - lists and iteration, joining
[  Section 11 ] Exploratory Analysis: Correlation & Violin
[  Section 12 ] PCA & UMAP
[  Section 13 ] Color Strategies
[  Section 14 ] Export (& plot data str.)
[  Section 15 ] Change root directory & here()
[  Section 16 ] Move files
[  Section 17 ] Row-wise calculations
[  Section 18 ] Text analysis
[  Section 19 ] qRT-PCR


[Installation of Packages]






[  Section 1  ]  ------------------ CUMULATIVE DISTRIBUTION, PERCENTILES & INTERVALS ------------------- ##




```{r}
diamonds %>%           #CDF scaled to max = 1
  arrange(price) %>% 
  ggplot(aes(x=price, y=cumsum(x)/sum(x))) +
  geom_point() +
  ylab("Cumulative Proportion")

diamonds %>%           #CDF scaled to sum total
  arrange(x) %>% 
  ggplot(aes(x=x, y=cumsum(x), color = x)) +
  geom_point() +
  ylab("Cumulative Sum") +
  scale_color_viridis()
```



Divide a vector into quantiles or fixed intervals

```{r}
tt <- rnorm(1000, 10, 5)

tt %>%        # divide data into intervals / bins
  sort() %>% 
  enframe() %>% 
  mutate(interval = map(.x = .$value, ~ cut(.x, breaks = seq(-5, 25, 5)))) %>%  #set breaks for intervals
  unnest(., interval) %>%
  ggplot(., aes(x = interval, y = value)) +
  geom_point(alpha = 0.3, shape = 21, fill = "green")
  

tt %>%        #quantile or percentile (ntile must have n = 100 for percentile)
  sort() %>% 
  enframe() %>% 
  mutate(n_tile = ntile(value, 100)) %>% 
  ggplot(., aes(x = value, y = n_tile)) + 
  geom_point(alpha = 0.3, shape = 21, fill = "blue")


```












[  Section 2  ]  ------------------- GRAPHPAD PRISM EXPORT --------------------- 


Randomly sample 200 rows from diamonds to speed up the test.

```{r}
library(tidyverse)
library(pzfx)

#Here I'm randomly subsampling diamonds to look at only 200 rows so that writing a pzfx file will not take a long time
set.seed(42)
diamondsRN <- diamonds %>% sample_n(200)
```

Add a column for the rownames, called row_names

```{r}

# Assign the "color" variable to be the rowname
# Use the make.unique() function here to create unique rownames. 
# R requires all rownames to be unique

#NOTE: this code does not create rownames, it creates a new variable called "row_names" that will later be assigned as techical rownames

diamondsRN <- diamondsRN %>%
  mutate(row_names = make.unique(as.character(diamondsRN$color)))
```


Nest on the cut

```{r}
#Break up the data into a list of tibbles based on a variable, in this case diamond "cut"
#This list of tibbles will become your data tables in Graphpad
nestedCut <- diamondsRN %>% nest(-cut)
#Show the resulting construct
nestedCut
```

Use map to change data to data frames with rownames:

```{r}
#Re-work each item in the list of data frames as follows

nestedCut <- nestedCut %>%
  mutate(data = map(data, ~ column_to_rownames(.x, var="row_names"))) %>% #Assign rownames to each tibble
  mutate(frames = map(data, as.data.frame)) %>%                           #make each tibble into a data.frame
  mutate(frames = map(frames, ~ select_if(.x, is.numeric)))               #Select only numeric data for export
nestedCut                                                                 #look at the resulting object:
```

Pull out the frames:

```{r}
#the pull function here extracts a list if five data.frames from the nestedCut variable

frames <- nestedCut %>% pull(frames)

#take a look at the fifth object in this list of data.frames
frames[[5]]

#assign names to frames. Each data.frame will get it's own name, and this name will become the data table name in Graphpad
#the desired names happen to be the list of names in the "cut" variable in the nestedCut object
#these names can be purlled out of nestedCut and assigned to be the names of frames
names(frames) <- nestedCut %>% pull(cut)
names(frames)
```

Write to one Graphpad file

```{r}
#pzfx documentation https://cran.r-project.org/web/packages/pzfx/pzfx.pdf

write_pzfx(frames, path = "test.PZFX",
           row_names = TRUE, x_col = NA) 

```

##Simpler Graphpad vignettes

Create 2 data tables in one .pzfx file

```{r}
x <- data.frame(A = c(2,3,4), B = c(4,6,9),C = c(0,5,2))
y <- data.frame(D = c(2,3,4), E = c(4,6,9), `F` = c(0,5,2))
z <- list(x,y)
write_pzfx(z, path = tempfile(fileext=".pzfx", pattern = "z", tmpdir = "C:/Users/kjwl754/Desktop"), row_names = FALSE, x_col = NA)
```

this also works as long as non-numeric data are removed

```{r}

iris_num <- iris %>%
  select(-Species)

iris_num %>%
  write_pzfx(path = tempfile(fileext=".pzfx", pattern = "iris_num", tmpdir = "C:/Users/kjwl754/Desktop"), row_names = FALSE, x_col = NA)
```


### Export using map2() to obtain multiple .pzfx files

#Nesting the data:

```{r}
iris2 <- iris %>% nest(-Species)

iris2 %>% map2(.x = .$data, .y = .$Species, 
               .f = ~ write_pzfx(.x, path = tempfile(fileext=".pzfx", 
                                                     pattern = paste0(.y), 
                                                     tmpdir = "C:/Users/kjwl754/Desktop"), 
                                 row_names = FALSE, x_col = 1))
```

#Export 3 DFs to one .pzfx file as separate data tables

```{r}
iris2 <- iris %>% nest(-Species)

Group_Names <- iris2$Species

iris2$data %>% write_pzfx(path = tempfile(fileext=".pzfx", 
                                      pattern = "iris2", 
                                      tmpdir = "C:/Users/kjwl754/Desktop"), 
                                      row_names = FALSE, x_col = 1) 
iris2$Species
```

#Export 3 DFs to one pzfx file as separate data tables with labels & rownames

```{r}
irisRN <- iris 

# Optional: throw in rownames
rownames(irisRN) <- make.unique(as.character(iris$Species)) 

split(irisRN, f = irisRN$Species)

iris.split <- as.list(split(select_if(irisRN, (is.numeric)), f = irisRN$Species))

write_pzfx(iris.split, path = tempfile(fileext=".pzfx", 
                                          pattern = "iris", 
                                          tmpdir = "C:/Users/kjwl754/Desktop"), 
                          row_names = TRUE, x_col = NA) 

```




Action: Choose column to use as rowname & choose variables on which to split data into tables & RUN
  Create rownames (optional)
  Create nesting variable

```{r}
#example... need to input D.j

D.rn <- D.j %>%
      #paste in column to make rownames
  mutate(row_names = make.unique(as.character(D.j$Grandparent))) %>%
      #paste in nesting columns with delimiter
  mutate(nestVar = paste0(FACS_Param, " _ ", param))

```

Nest on the cut

```{r}
nestedCut <- D.rn %>% nest(-nestVar)
nestedCut
```

Use map to change data to data frames with rownames:

```{r}
nestedCut <- nestedCut %>%
  mutate(data = map(data, ~ column_to_rownames(.x, var="row_names"))) %>%
  mutate(frames = map(data, as.data.frame)) %>%
  mutate(frames = map(frames, ~ select_if(.x, is.numeric)))
nestedCut           
```

Pull out the frames:

```{r}
frames <- nestedCut %>% pull(frames)
frames[[5]]
names(frames) <- nestedCut %>% pull(nestVar)
names(frames)
```

Action: rename the exported .pzfx file
  Write to Graphpad file

```{r}
write_pzfx(frames, path = "test.PZFX", 
           row_names = TRUE, x_col = NA) 
```















[  Section 3  ]  -------- IMPORT MULTIPLE FILES AS SEPARATE DATA FRAMES -------- ##

```{r}

setwd("C:/Users/kjwl754/Desktop")

### Importing lists of files based on 
### common file name or file type

#import all excel files
temp = list.files(pattern="*.xlsx")
myfiles = lapply(temp, read_excel)
length(myfiles)
temp

#import on common file name
temp = list.files(pattern="DF.*.xlsx")
myfiles = lapply(temp, read_excel)
length(myfiles)
temp

#import csv files using read.delim
temp = list.files(pattern="DF*.csv")
myfiles = lapply(temp, read.delim)
length(myfiles)
temp

# Write out single data frames
for (i in seq(myfiles))
  assign(paste0("Table_", i), myfiles[[i]])

nest(-myFactor)

map2(x,y, ~ write.excel(.x, filename paste(.y,",xlsx", , sep=" ")))

```









[  Section 4  ]  ------------------  FACS Stats Cleanup -------------------- ##






```{r}

subtitle <- paste("AKBird ", Sys.Date())

ExpDate <- "210318"

      # Use this only if script in different location to data files
#ExperimentDirectory <- "C:/Users/kjwl754/Box Sync/Projects/LOX1/ab200909 GMCSF LOX #T suppression TEST2"
#list.dirs(path = here(), full.names = TRUE, recursive = FALSE) 
#knitr::opts_knit$set(root.dir = normalizePath(ExperimentDirectory)) 

dir()    #   <- Find File Here

prelim.list <- list.files(".", ".csv")

paste0(cat(prelim.list), "   <-- Desired files in correct order?")


```



# MAY NEED TO REMOVE FILTERING ON METADATA
Run

```{r}
csv.list <- prelim.list
# Import raw FACS stats

excel.list <- csv.list %>% str_replace(., ".csv", ".xlsx") # Create list of .xlsx files

filename.list <- str_replace(excel.list, ".xlsx", "")

map2(.x = csv.list, .y = excel.list, ~ convert(paste0(.x), paste0(.y)))            # Convert .csv to .xlsx

D.raw <- map(.x = excel.list, ~ read_xlsx(paste0(.x))) %>%                         # Read in .xlsx data
  set_names(filename.list) %>% 
  bind_rows(., .id = 'Plate')

paste0("Dimensions of combined FACS data") 
dim(D.raw)

# Importing meta data

FileNameFACS <- paste0("ab", ExpDate, " Assay.xlsx")

# FileNameFACS <- "ab200817 Assay"

D.meta <- read_excel(paste0(FileNameFACS), sheet = "Conditions")

paste0("Dimensions of combined meta data") 
dim(D.meta)

```




Run - Looks accurate?

```{r, fig.width = 14, fig.height = 4}
not_all_na <- function(x) any(!is.na(x))

D.rn <- D.raw %>%                                          
  mutate(ID_Tag = str_extract(V1, "(\\d+).fcs")) %>%
  mutate(ID_Tag = str_remove(ID_Tag, ".fcs")) %>%
  select_if(not_all_na) %>%
  mutate_at(vars(ID_Tag), as.numeric) %>%
  mutate(Specimen = map_chr(V1, ~ str_split(.x, "_")[[1]][2])) %>%    # Pull out DIVA "specimen" information
  mutate_at(vars(Specimen), as.numeric) %>%
  arrange(Specimen, ID_Tag) %>%
  filter(!grepl('FMO', V1)) %>%
  filter(V1 != "SD") %>%
  filter(V1 != "Mean") %>% 
  mutate(ID_Tag = Specimen)

D.rn %>% ggplot(., aes(x = Specimen, y = fct_rev(Plate))) + geom_point() + geom_text(aes(label = ID_Tag), hjust = 0.5, vjust = -1, color = "blue") + labs(title = "Is plate sample list correct?", subtitle = "Specimen = BLUE")

```



Run - Looks accurate?

```{r, fig.width = 12, fig.height = 8}

(D.temp <- D.rn %>% 
  mutate(well = map_chr(V1, ~ flatten(str_split(.x, "_"))[3] %>% unlist())) %>%
  #group_by(well) %>% 
  #mutate(Plate = 1:length(`well`)) %>% 
  #ungroup() %>%   
  separate(well, c("well_row", "well_col"), sep = 1))

D.key <- D.temp %>% select(Plate, ID_Tag, Specimen) %>% 
  distinct() %>% 
  arrange(Plate, Specimen) %>%
  mutate(newidtag = D.meta$ID_Tag)
  #mutate(newidtag = 1:nrow(.))

D.key %>% kable()  

D.temp

D.temp %>% left_join(., D.key, by = c("Plate", "ID_Tag", "Specimen")) %>%     #  Checking D.key for accuracy
  select(ID_Tag, Specimen, Plate, well_row, well_col, newidtag) %>%
  ggplot(., aes(x = fct_inseq(`well_col`), y = fct_rev(well_row))) +
  geom_point() +
  geom_text(aes(label=ID_Tag), hjust=-0.5, vjust=0.5, color = "red") +
  geom_text(aes(label=Specimen),hjust=0.5, vjust=-0.5, color ="blue") +
  geom_text(aes(label=newidtag),hjust=1, vjust=1, color ="orange") +
  facet_wrap(~Plate, ncol = 2) +
  labs(title = "Plate mapping from DIVA", 
       subtitle = "ID Tag = RED, Specimen = BLUE, newidtag = ORANGE\nCheck numbers for accuracy. Is plate # correct?\nAdjust D.key until newidtag [ ORANGE ] is correctly maps to metadata", caption = ExpDate) +
  theme_fivethirtyeight()

#remove non-important elements from D.key
D.key <- D.key %>% select(-Specimen)

```


Join D.rn & D.key

```{r}
D.key
D.rn <- D.rn %>% left_join(., D.key, by = c("Plate", "ID_Tag")) %>%
  mutate(ID_Tag = newidtag) %>% select(-newidtag)

D.rn %>% names() %>% kable()  #Do not delete this; use for next chunk

```



INPUT: paste in readout colnames & Run


```{r}

D.l <- D.rn %>%                           #Convert to long format
  gather(key = "FACS_Param", value = "Readout", 
         `FSC SSC/Singlets/Live | Mean (LOX-1)`:`FSC SSC/Singlets/Live | Mean (LOX-1)`)

```


Run
Optional: Maybe add "-" to some parameter names (eg PD-L1)

```{r}

D.p <- D.l %>%
  mutate(param = str_extract(FACS_Param, "(?<=\\|)[^\\/]+")) %>%
  mutate(param = gsub(pattern = "Mean", replacement = "MFI", x = .$param)) %>%
  mutate(param = gsub(pattern = "\\(", replacement = "", x = .$param)) %>%
  mutate(param = gsub(pattern = "\\)", replacement = "", x = .$param)) %>%
  mutate(Gate = str_extract(FACS_Param, "(?<=\\/)[^\\/]+(?=\\|)")) %>%
  mutate(ParentGate = str_extract_all(.$FACS_Param, regex("(?<=\\/)[^\\/]+(?=\\/)", multiline = TRUE))) %>%
  mutate(ParentGate = unlist(unique(map(.[,"ParentGate"], function(x) {map(x, last)})))) %>%
  mutate(param =  str_replace_all(.$param, "Freq. of Parent %", paste0(Gate, " (% freq. of ", ParentGate, ")"))) %>%
  mutate(param = gsub(pattern = "HLA ", replacement = "HLA\\-", x = .$param)) 

dim(D.l)
dim(D.p)
paste0("Added 3 cols?")
```





Is this TRUE?

```{r}
#check that metadata and data match (are from same exp)
nrow(D.meta) == length(unique(D.p$ID_Tag))

```




Join data and check joined DF

```{r}
join.to.metadata <- function(D.1, D.2) {
  left_join(D.1, D.2, by = "ID_Tag")
}

colnames(D.p)[colnames(D.p) == agrep(pattern="idtag", x=names(D.p), max.distance=0.1, value=TRUE, ignore.case=TRUE)] <- "ID_Tag"
colnames(D.meta)[colnames(D.meta) == agrep(pattern="idtag", x=names(D.meta), max.distance=0.1, value=TRUE, ignore.case=TRUE)] <- "ID_Tag"

D.j <- join.to.metadata(D.1 = D.p, D.2 = D.meta)

# Remove white space

D.j <- D.j %>% mutate(across(is.character, trimws))    
names(D.j) <- map(names(D.j), ~ trimws(.x)) 

# add Greek letters

D.j <- D.j %>% mutate(across(is.character, toGreek))
names(D.j) <- as.list(names(D.j)) %>% map_chr(., ~ toGreekLiteral(.x))

# rbind(head(D.j, 15), tail(D.j, 15)) %>% view()             # Check the join

names(D.j)
```



Run

```{r, fig.height = 3}
         #Export cleaned & merged data

D.export <- D.j  

write_xlsx(x = D.export, path = paste0(ExpDate, " FACSstats CleanedMerged.xlsx"), col_names = TRUE) 

paste("Experiment Parameters for Plot")
D.meta %>% names() 
```


######    PLOTS    #####



FIRST:      Make sure y axis max == the replicate number

```{r, fig.width = 30, fig.height = 15}

unique(D.j$Gate)

D.j

D.j %>% names()

(p.reps <- D.j %>% 
  ggplot(., aes(x = as.factor(`ID_Tag`), fill = `Gate`)) +
  geom_bar(stat = "count", position = "dodge") +
  facet_grid(`Donor ID` ~ `GM-CSF (ng/mL)` + `CRP (ug/mL)` + `param`, labeller = label_both) +
  scale_fill_brewer(palette = "Set1") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)))

```


Make experiment tailored adjustments


```{r}

D.j <- D.j %>% 
  group_by(param,ID_Tag) %>% 
  mutate(avgReadout = mean(Readout)) %>% 
  ungroup() %>% 
  select(-Readout, -V1, -Specimen) %>% 
  distinct()

#D.j <- D.j %>% mutate(Gate = ifelse(Gate == "no prolif. ", "0div.", Gate)) %>%
#  mutate_at(vars(`Beads/well (uL)`), ~round(.,2))
```



Filtering out controls to look @ suppression data






ROS production by neu and mono

```{r, fig.width = 10, fig.height=5}

# (main.stims <- unique(D.j$`Stim. type`)[!unique(D.j$`Stim. type`) %in% c(NA, "Unstim")])
# 
# (p.stim.list <- map(main.stims, ~ D.j %>% filter(`Stim. type` %in% c(.x, "Unstim"),
#                                  param %in% "Cell ROX high  (% freq. of Live)") %>% 
#   ggplot(., aes(x = factor(Dose), y = Readout, fill = as.factor(`Donor ID`))) +
#   geom_bar(stat = "summary", fun = "mean", position = position_dodge(), alpha = 0.5) + 
#   geom_point(position = position_dodge(width = 0.9), color = "black", alpha = 0.5) + 
#   #geom_text(aes(label = `ID_Tag`)) +
#   facet_wrap(~`Cell type`) +
#   theme(strip.background = element_rect(color="white", fill="#FFFFFF", size=0), 
#         strip.text = element_text(colour = 'black', size = 12, face = "bold", hjust = 0),
#         axis.text.x = element_text(angle = 45, hjust = 1),
#         plot.subtitle = element_text(color = "ivory", hjust = 1, size = 8)) +                                             
#   #stat_summary(position = position_dodge(width = 0.9), fun.data=mean_se, fun.args = list(mult=1),
#   #      geom="errorbar", color="black", width=0.2, size = 0.5) +
#   #stat_summary(position = position_dodge(width = 0.9), fun="mean", geom="point", color="black") +
#   labs(x = paste("Dose ", .x), 
#        y = "Cell ROX high  (% freq. of Live)", 
#        title = paste(.x, " tx neutrophils"), 
#        subtitle = subtitle, 
#        caption = ExpDate) +
#   scale_fill_ipsum(name = "Donor ID")))

p.LOX <- D.j %>%
  ggplot(., aes(x = fct_reorder(Condition, ID_Tag), y = avgReadout)) +
  geom_bar(stat = "summary", fun = "mean", alpha = 0.5, color = "black", aes(fill = factor(`CRP (ug/mL)`))) + 
  geom_jitter(width = 0.2, color = "black", alpha = 0.5, aes(shape = factor(`Donor ID`))) + 
  #geom_text(aes(label = `ID_Tag`)) +
  #facet_wrap(~.x, scales = "free") +
  theme(strip.background = element_rect(color="white", fill="#FFFFFF", size=0), 
        strip.text = element_text(colour = 'black', size = 12, face = "bold", hjust = 0),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.subtitle = element_text(color = "ivory", hjust = 1, size = 8),
        plot.margin = unit(c(0.2, 0.2, 0.2 ,0.5), "in")) +                                             
  stat_summary(position = position_dodge(width = 0.9), fun.data=mean_se, fun.args = list(mult=1),
        geom="errorbar", color="black", width=0.2, size = 0.5) +
  stat_summary(position = position_dodge(width = 0.9), fun="mean", geom="point", color="black") +
  scale_fill_brewer() +
  scale_y_continuous(labels = label_number_si()) +
  labs(title = "LOX-1 expression w/ GM-CSF & CRP O/N Tx", y = "MFI LOX-1", x = NULL, fill = "CRP dose\n(\u03bcg/mL)", shape = "Donor")

PlotName <- "LOX expression w GM-CSF_CRP O_N tx"

ggsave(paste0("ab", ExpDate, "_", PlotName, ".tiff"), p.LOX, height = 5, width = 7, dpi = 300)

# walk2(.x = p.list, .y = 1:length(p.list), ~ ggsave(paste0("ab", ExpDate, "_", PlotName, "_", .y, ".tiff"), .x, height = 5, width = 9, dpi = 300))

```
















[  Section 5  ] ---------------- Correlations ------------------





The quick method

correlation heat maps

```{r}

library(MASS)
library(lsr)

# correlation co-efs

m <- Housing %>% select_if(is.numeric) %>%
  correlate(test = "spearman") %>% .[1] %>% as.data.frame() %>% as.matrix() 

colnames(m) <- map_chr(.x = colnames(m), ~ str_remove(.x, "correlation."))

m %>% pheatmap(na_col = "grey", main = "correlation co-eff.", color=cubehelix(50)) 

# pvalues

p <- Housing %>% select_if(is.numeric) %>%
  correlate(test = "spearman") %>% .[2] %>% as.data.frame() %>% as.matrix() #%>% log(., 10)  

colnames(p) <- map_chr(.x = colnames(p), ~ str_remove(.x, "p.value."))

p %>% pheatmap(na_col = "grey", treeheight_col = 20)

pdf("myplot.pdf")

m %>% pheatmap(na_col = "grey", 
               main = "spearman rho", 
               width = 5, height = 5, 
               fontsize_col = 11, 
               annotation_legend = TRUE) 
p %>% pheatmap(na_col = "grey", 
               main = "p-value", 
               treeheight_col = 50, 
               fontsize = 18, 
               dendrogram = 'none', 
               color=colorRampPalette(c("navy", "white", "red"))(50))
mtcars %>% scale(.) %>% pheatmap()
# plot.new()
# textbox(c(0,0.2), 1, c("many words","more words","why not?", "keep going",rep("and going",10)))

dev.off()

```




```{r include = FALSE}
knitr::opts_chunk$set(echo=FALSE)
```

# INPUTS for correlation


```{r}
importedFileName <- "ENTERFILENAMEwoutEXT"
#DF.input <- read_excel(paste0(importedFileName, ".xlsx"))

DF.input <- sample_n(diamonds, 200)

DF.input %>% head(n = 10)

ExpDate <- "000000"

folder.sig <- paste0("ab", ExpDate, " signif correlations")
folder.all <- paste0("ab", ExpDate, " all correlations")
folder.HM <- paste0("ab", ExpDate, " correlation heat maps")

```

# Calc correlation

```{r, fig.height = 14, fig.width = 10}
mydata_all <- DF.input

mydata <- DF.input %>%
  select_if(is.numeric)

mydata <- as.matrix(mydata)
cor_3 <- rcorr(as.matrix(mydata), type = "spearman")

#convert to long format
flat_cor_mat <- function(cor_r, cor_p) {
  cor_r <- rownames_to_column(as.data.frame(cor_r), var = "row")
  cor_r <- gather(cor_r, column, cor, -1)
  cor_p <- rownames_to_column(as.data.frame(cor_p), var = "row")
  cor_p <- gather(cor_p, column, p, -1)
  cor_p_matrix <- left_join(cor_r, cor_p, by = c("row", "column"))
  cor_p_matrix
}

my_cor_matrix <- flat_cor_mat(cor_3$r, cor_3$P) %>%     # Tabulate all correlation stats
  mutate(rho = round(cor, 5)) %>%
  mutate(FDR = round(p.adjust(p, "BH"), 5)) %>%
  filter(cor !=1, !is.na(p))

threshold.note <- "Data are statistically signif at spearman FDR10 and rho > abs(0.7)"

filtered_cor_data <- my_cor_matrix %>%                  # Tabulate only significant corr stats
  filter(FDR <= 0.1) %>%
  filter(rho >= 0.7 | rho <= -0.7) %>%
  distinct()

                         # Eliminate redundancy

uniquepairs <- filtered_cor_data %>%               # Generates DF with all possible permutations of columns to be correlated
  filter(row != column) %>% 
  select(row, column) %>% 
  apply(., 1, sort) %>% 
  t() %>% 
  as_tibble() %>% 
  distinct()

response <- uniquePairs$Resp                       # Change which is response by switching "expl" and "response" here
expl <- uniquePairs$Expl
response = set_names(response, response)
expl <- set_names(expl, expl)

dat <- mydata_all #What data are being correlated

sig_plots <- map2(response, expl, ~ ggplot(dat, aes(x = .data[[.x]], y = .data[[.y]])) +
    #geom_point(alpha = 0.2) +
    #stat_density_2d(aes(fill = ..level..), bins = 30, geom = "polygon") +
    geom_pointdensity(adjust = 0.5) +
    #stat_density2d(geom = 'polygon') +
    scale_color_viridis() +
    theme_bw() +
    scale_x_continuous(limits = NULL) +
    labs(x = .x,
         y = .y) +
    #scale_x_continuous(trans='log10') +
    #scale_y_continuous(trans='log10')
    theme(legend.position="none"))                     # plot all relationships w/out redundancy

var.names <- colnames(mydata)

var.combo.table <- crossing(var1 = var.names, var2 = var.names) %>% filter(var1!=var2) 

response <- var.combo.table$var1                       # Change which is response by switching "expl" and "response" here
expl <- var.combo.table$var2
response = set_names(response, response)
expl <- set_names(expl, expl)

dat <- mydata_all #What data are being correlated

all_plots <- map2(.x = expl,.y = response, ~ ggplot(dat, aes(x = .data[[.x]], y = .data[[.y]])) +
    #geom_point(alpha = 0.2) +
    #stat_density_2d(aes(fill = ..level..), bins = 30, geom = "polygon") +
    geom_pointdensity(adjust = 0.5) +
    #stat_density2d(geom = 'polygon') +
    scale_color_viridis() +
    theme_bw() +
    scale_x_continuous(limits = NULL) +
    labs(x = .x,
         y = .y) +
    #scale_x_continuous(trans='log10') +
    #scale_y_continuous(trans='log10')
    theme(legend.position="none"))

```






   # View & export plots w signif correlations & statistics for all correlations
   

```{r, fig.width = 8, fig.height = 12}

pre <- Sys.time()
(p.sig <- sig_plots %>% marrangeGrob(., nrow = 3, ncol = 2, bottom = paste0(ExpDate, "    ", threshold.note)))
post <- Sys.time()

dir.create(folder.sig)

if ( difftime(post, pre, units="secs")[[1]] < 12 ) {

  ggsave(paste0(ExpDate, " signif corr plots.pdf"), p.sig, path = here(folder.sig), height = 11, width = 7)

} else {

sig_plots <- sig_plots #& plot_annotation(caption = paste0(threshold.note))

walk2(.x = sig_plots, .y = c(1:length(sig_plots)), 
      ~ ggsave(paste0(ExpDate, " signif corr_", .y, ".tiff"), 
               path = here(folder.sig), .x, height = 5, width = 5, dpi = 300))
}
setwd(here(folder.all))
write_xlsx(my_cor_matrix, paste0(ExpDate, "_SpearCorr STATS.xlsx"))
```





   # Export all plots
    

```{r, fig.width = 8, fig.height = 12}

pre <- Sys.time()
(p.sig <- all_plots %>% marrangeGrob(., nrow = 3, ncol = 2, bottom = paste0(ExpDate)))
post <- Sys.time()

dir.create(folder.all)

if ( difftime(post, pre, units="secs")[[1]] < 12 ) {

  ggsave(paste0(ExpDate, " all corr plots.pdf"), p.sig, path = here(folder.all), height = 11, width = 7)

} else {

sig_plots <- sig_plots #& plot_annotation(caption = paste0(threshold.note))

walk2(.x = sig_plots, .y = c(1:length(sig_plots)), 
      ~ ggsave(paste0(ExpDate, " corr_", .y, ".tiff"), 
               path = here(folder.all), .x, height = 5, width = 5, dpi = 300))
}

```

 

Export rho and p correlelograms

```{r, fig.height = 14, fig.width = 10}
#  Reference for correlogram       http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram

dir.create(folder.HM)
setwd(here(folder.HM))

col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))

pdf(file = paste0(ExpDate, " spearcor_rho.pdf"))
p.rho <- mydata %>%               #corr plot method = 'arg' should be one of “circle”, “square”, “ellipse”, “number”, “shade”, “color”, “pie”
  cor(method = "spearman") %>% 
  corrplot(., type="upper", 
           method = "color", 
           addCoef.col = "black",
           col=col(200),
           order="FPC", 
           tl.col="black", 
           tl.srt=45, 
           sig.level = 0.01, 
           insig = "blank", 
           diag=FALSE)

cor_3[["P"]][is.na(cor_3[["P"]])] <- 0                   # P value heat map
pcormat <- cor_3[["P"]] %>% round(., 4)
pcormat %>% range()
dev.off()

pdf(file = paste0(ExpDate, " spearcor_pvals.pdf"))
p.pval <- pcormat %>% 
  corrplot(., type="upper", 
           method = "circle", 
           addCoef.col = "black",
           order="FPC", 
           tl.col="black", 
           tl.srt=45, 
           sig.level = 0.01, 
           cl.length = NULL,
           cl.lim = range(pcormat),
           insig = "blank", 
           diag=FALSE)
dev.off()
```











[  Section 6  ]  ------------------ ELISA Cleanup ---------------------- 

#Choose working directory
#Paste in filename & RUN

```{r}

filename <- "ab200218 IFN ELISA multiStim5" ## <- EDIT ALL THREE OF THESE 
workingdirectory <- "C:/Users/kjwl754/Desktop/"
meta_filename <- "ab200211 Assay"  
#-------------#
setwd(paste0(workingdirectory))
ELISA_DF <- read_excel(paste0(filename, ".xlsx"), col_names=TRUE)

ELISA_DF_fill <- ELISA_DF %>% 
  tidyr::fill(Sample, AvgConc, SD, CV, Dilution, AdjConc)

ELISA_DF_varname_dedup <- ELISA_DF_fill[ELISA_DF_fill$Sample != "Sample" , ]

ELISA_DF_varname_dedup$Sample <- gsub("Un", "", paste(ELISA_DF_varname_dedup$Sample))

names(ELISA_DF_varname_dedup)[names(ELISA_DF_varname_dedup) == 'Sample'] <- 'ID_Tag'

ELISA_DF_OOR <- ELISA_DF_varname_dedup 
#View(ELISA_DF_OOR)

ELISA_DF_OOR$OD <- as.numeric(ELISA_DF_OOR$OD)
ELISA_DF_OOR$Conc <- as.numeric(ELISA_DF_OOR$Conc)
ELISA_DF_OOR$Dilution <- as.factor(ELISA_DF_OOR$Dilution)

ggplot(data = ELISA_DF_OOR) + 
  geom_point(mapping = aes(x = OD, y = Conc, color=Dilution)) +
  scale_y_continuous() +
  scale_x_log10() +
  scale_y_log10()

```


#Input preferred dilution & RUN

```{r}
pref.dil <- "Use200"

DF.range <- ELISA_DF_OOR %>% 
  mutate(NewCol = Conc) %>%
  mutate(NewCol = ifelse(is.na(Conc) & OD < 0.1, 0, NewCol)) %>%
  mutate(NewCol = ifelse(is.na(Conc) & OD > 0.6, NA, NewCol)) %>%
  mutate(`AnalyteConc` = NewCol*as.numeric(as.character(Dilution))) %>%
  arrange(ID_Tag)

view(DF.range)
```

#Optional: Export "...Cleaned.xlsx" file NO METADATA YET

```{r}
setwd(paste0(workingdirectory))
write_xlsx(x = DF.range, path = paste0(filename, "_", pref.dil, "_", "Cleaned.xlsx"), col_names = TRUE)

```

#Join cleaned instrument readout to metadata
  #Check lines individually to ensure join works properly

```{r}

setwd(paste0(workingdirectory))
DF.md <- read_excel(path = paste0(workingdirectory, meta_filename, ".xlsx"), sheet = "Conditions")

colnames(DF.md)[colnames(DF.md) == agrep(pattern="idtag", x=names(DF.md), max.distance=0.1, value=TRUE, ignore.case=TRUE)] <- "ID_Tag"

DF.md

#view(DF.range)   #LOOK AT AND MODIFY INSTRUMENT READOUT PRIOR TO JOIN
#DF.range <- DF.range %>% separate(col = `ID_Tag`, into = c("ID_Tag", "junkCOL"), sep = "_") %>% select(-c("junkCOL"))
DF.range$ID_Tag <- as.numeric(DF.range$ID_Tag)
DF.range$ID_Tag

#MAKE SURE INSTRUMENT DATA AND METADATA HAVE THE SAME No. OF CONDITIONS
cat("This is generally TRUE: ->   ", length(unique(DF.range$`ID_Tag`)) == length(unique(DF.md$ID_Tag)))
setdiff(unique(DF.range$`ID_Tag`), unique(DF.md$ID_Tag))


#LEFT JOIN OF DATA TO METADATA
D.j  <- DF.range %>% inner_join(y = DF.md, by = "ID_Tag")

dim(DF.md)
dim(DF.range)
dim(D.j)

view(D.j)

```

#If merged data looks good, export "...CleanedMerged.xlsx" file

```{r}
ELISA_DF <- DF.range #CleanedMerged R object

setwd(paste0(workingdirectory))
write_xlsx(x = D.j, path = paste0(
  filename, "_", pref.dil, "_", "CM.xlsx"), col_names = TRUE)

```











[  Section 7  ] ----------------          Plotting           ------------------##





```{r, fig.width = 10, fig.height = 6}

library(lazyeval)
library(scales)
library(MASS)


ExpDate <- "000000"
    
df = Housing
x = "lotsize"
y = "price"
xfacetlist = c("bedrooms")
yfacetlist = c("driveway")
title = "Title"
caption = ExpDate
subtitle = "subtitle"
tag = paste("Last modified: ", Sys.Date(), " Author: AKBird")
colorvar = x
xlab = x
ylab = y 


faceter = if(!is.null(xfacetlist) & !is.null(yfacetlist)) {
    paste(paste(xfacetlist, collapse = " + "), "~", paste(yfacetlist, collapse = " + ")) 
    } else if (!is.null(xfacetlist) & is.null(yfacetlist)) {
    paste("~", paste(xfacetlist, collapse = " + "))
    } else if (is.null(xfacetlist) & !is.null(yfacetlist)) {
    paste(paste(yfacetlist, collapse = " + "), "~ .")
    } else {print(NULL)}
 

p.1 <- ggplot(df, aes(.data[[x]], .data[[y]], fill = .data[[colorvar]])) + 
        geom_point(alpha = 0.6, color = "black", shape = 21) +
        facet_grid(paste(faceter), labeller = "label_both") +
        theme(strip.background = element_rect(color="white", fill="#FFFFFF", size=0), strip.text = element_text(colour = 'black', size = 12, face = "bold", hjust = 0),
              axis.text.x = element_text(angle = 45, hjust = 1),
              #plot.subtitle = element_text(color = "ivory", hjust = 1, size = 8),
              legend.position = "none") +
        scale_y_continuous(labels = label_number_auto()) +
        scale_x_continuous(labels = label_number_auto()) +
        labs(title = title, 
             caption = caption,
             x = xlab,
             y = ylab,
             subtitle = subtitle,
             tag = tag) +
        labs(caption = caption) +
        scale_fill_viridis(discrete = ifelse(is.discrete(df[[colorvar]]), T, F))
        
p.1

```


Generic experiment plotting

```{r}
setwd("C:/Users/kjwl754/Desktop")

#CleanedMerged ELISA data (with metadata) is called "ELISA_DF" 

###Import DFs

#Assay readout
D.1 <- as_tibble(read_excel(file.choose(), sheet=1))

#Assay setup/metadata
D.2 <- as_tibble(read_excel(file.choose(), sheet="Conditions"))

###Join DFs

colnames(D.1)[colnames(D.1) == agrep(pattern="idtag", x=names(D.1), max.distance=0.1, value=TRUE, ignore.case=TRUE)] <- "ID_Tag"
colnames(D.2)[colnames(D.2) == agrep(pattern="idtag", x=names(D.2), max.distance=0.1, value=TRUE, ignore.case=TRUE)] <- "ID_Tag"

join.to.metadata <- function(D.1, D.2) {
  left_join(D.1, D.2, by = "ID_Tag")
}

D.j <- join.to.metadata(D.1, D.2)

view(D.j)

###Convert wide -> long format (use for FACS data)

D.g <- gather(D.j, key = "key", value = "value", ..., na.rm = FALSE,
       convert = FALSE, factor_key = FALSE)

View(D.j)

colnames(D.j) <- gsub(" ", "_", names(D.j))
colnames(D.j) <- gsub("-", "_", names(D.j))
colnames(D.j) <- gsub("//(", "", names(D.j))
colnames(D.j) <- gsub(")", "", names(D.j))
colnames(D.j) <- gsub("/", "_", names(D.j))



####Format: -- >  data %>% stats.to.plot(groupingColumns, analytes)     < --

names(D.j)

unique(ggInput$Dilution)

ggInput <- D.j %>%
  filter(Dilution == 10, Dilution == 20)

head(ggInput, n = 30)
tail(ggInput, n = 30)

##Arguments  stats.to.plot(data, groupingColumns, analytes)

###Optional: Generate aggregate stats for plotting

#run function
stats.to.plot <- function(data, groupingColumns, analytes) {
  require(dplyr)
  # create variable with all required columns
  # select(!!! rlang::syms(allColumns)) %>%
  allColumns <- c(groupingColumns, analytes)
  data %>%
    gather(analyte, value, !!! rlang::syms(analytes)) %>%
    group_by_at(c(groupingColumns, "analyte")) %>%
    summarise(x.axis = unique(condition_title),
              mean_PL = mean(as.numeric(value), na.rm=TRUE),
              sd_PL = sd(value),
              n_PL = length(value),
              SE_PL = sd(value)/sqrt(length(value))) %>%
    ungroup()
}

ggInput <- ggInput %>%
  stats.to.plot(c(`condition_title`), c("AnalyteConc")) # %>%
  # head(30) %>%
  # kable()


########################

names(ggInput)

diamonds_2 <- diamonds[1:200,]

diamonds_2 %>% group_by_if(.predicate = c(clarity == "SI2"))



DMD <- as_tibble(diamonds_2) %>% nest(-c(cut == "Ideal")) 
DMD

DMD$data[[4]]

diamonds_2 <- diamonds_2 %>%
  mutate(Index = seq.int(1:nrow(diamonds_2))) %>%
  select(Index, everything())

map2(.x = DMD$data, .y = DMD$carat, .f =
       ~ ggplot(.x, aes(x = .x$table, y = .x$depth,)) +
       geom_point(aes(fill = .x$z), shape = 21, color = "black", size = 2) +
       scale_fill_viridis(name="z (mm)") +
       ggtitle(paste0("Carat: ", .y)) +
       xlab("Table") +
       ylab("Depth"))

ggplot(DMD$data[[4]], aes(x = color, y = depth)) +
         geom_bar(stat = "identity", aes(fill = color)) +
                    scale_fill_viridis_d()

map2(.x = DMD$data, .y = DMD$carat, 
     .f = ~ ggplot(.x, aes(x = .x$color, y = .x$depth,)) +
       geom_bar(position=position_dodge(), stat="summary", fun.y = "mean", 
                aes(fill = color), alpha = 0.5, color = "black", width = 0.7) + 
       geom_jitter(width = 0.2, alpha = 0.5, size = 2,
                   shape = 21, color = "black", fill = NA) +
       stat_summary(fun.data=mean_se, fun.args = list(mult=1),   # ERROR BARS
                    geom="errorbar", color="black", width=0.2) +
       scale_fill_viridis_d(name="color") +
       ggtitle(paste0("Carat: ", .y)) +
       xlab("Table") +
       ylab("Depth"))[[100]]

dim(DMD)

DMD$data[[2]]

head(diamonds)
##-------Order by multiple variables and ggplot

names(ggInput)

ggInput <- ggInput %>%
  arrange(desc(CpGA), Tumor_cell_line, Axitinib_dose_nM) %>%
  mutate(Index = seq.int(nrow(ggInput)))

ggInput$x.axis <- factor(ggInput$x.axis, levels = unique(ggInput$x.axis[order(ggInput$Index)]))

# Use map with filter to get complex groupings


qq <- diamonds_2 %>% filter(cut == "Ideal" | clarity == "SI2")

CUT <- diamonds_2$cut

length(CUT)

## REFINE THIS
map2(.x = diamonds_2, .y = CUT, 
     .f = ~ filter(.x, cut == .x$.y | .x$clarity == "SI2"))

view(qq)

as_tibble()

ggInput %>%
  ggplot(mapping=aes(x=x.axis, y=mean_PL, fill=Tumor_cell_line)) + 
  geom_bar(stat = 'identity', position='dodge', width=0.75) +
  geom_errorbar(aes(ymin = mean_PL - SE_PL, ymax = mean_PL + SE_PL), size=1, width=0.5) +
  facet_grid(Donor_ID ~ .) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  xlab(NULL) +
  ylab('Pan-hIFNalpha (pg/mL)') +
  scale_y_continuous(labels = function(x) format(x, scientific = TRUE))

```


Multi-line x axis using interaction()

```{r}
library(ggh4x)
mtcars %>% ggplot(., aes(interaction(gear, cyl, sep = "\n"), `mpg`, fill = factor(gear))) +
  geom_bar(stat = "summary", fun = "mean") +
  scale_x_discrete(guide = guide_axis_nested(delim = "\n"))

```



Survival plots

Source https://rpkgs.datanovia.com/survminer/

```{r}
#if(!require(devtools)) install.packages("devtools")
#devtools::install_github("kassambara/survminer", build_vignettes = FALSE)

library("survminer")

fit <- survfit(Surv(time, status) ~ sex, data = lung)

ggsurvplot(fit, data = lung)
```


```{r}
ggsurvplot(
  fit,
  data = lung,
  size = 1,                 # change line size
  palette =
    c("#E7B800", "#2E9FDF"),# custom color palettes
  conf.int = TRUE,          # Add confidence interval
  pval = TRUE,              # Add p-value
  #risk.table = TRUE,        # Add risk table
  risk.table.col = "strata",# Risk table color by groups
  legend.labs =
    c("Male", "Female"),    # Change legend labels
  risk.table.height = 0.25, # Useful to change when you have multiple groups
  ggtheme = theme_bw()      # Change ggplot2 theme
)
```




Time series

data from link below;  download the .csv
https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/HTTWYL

Lubridate

```{r}
protests <- vroom("C:/Users/kjwl754/Desktop/mmALL_073120_csv.csv")
protests %>% glimpse()

protests.simp <- protests %>% select(country, startday, startmonth, startyear)
protests.simp %>% 
  mutate(start_date = str_c(startyear, "-", startmonth, "-", startday)) %>% #combines date info into chr string
  count(start_date, country) %>%
  mutate(start_date = lubridate::ymd(start_date))
```


Tsibble - plot time series

```{r}
protests.simp %>% mutate(start_month = tsibble::yearmonth(start_date)) %>%
  count(start_month) %>%
  ggplot(aes(x = start_month, y = n)) + geom_line()
```




Vectorized Mandelbrot

```{r}

cols <- colorRampPalette(c("blue", "yellow", "red", "black"))(11)

xmin = -1.5
xmax = 1.5
ymin = -1.5
ymax = 1.5
nx = 5000
ny = nx
n = 40

x <- seq(xmin, xmax, length.out=nx)
y <- seq(ymin, ymax, length.out=ny)
c <- outer(x,y*1i, FUN = "+")          # array containing coordinates
z <- matrix(0.0, nrow = length(x), ncol = length(y))   #array initiating @ 0
k <- matrix(0.0, nrow = length(x), ncol = length(y))  #array initating @ 0

for (rep in 1:n) {
  print(rep)
  index <- which(Mod(z) < 50)
  z[index] <- z[index]^2 + c[index]
  k[index] <- k[index] + 1
}

image(x,y,k,col = cols)

```







[  Section 8  ] ------------ ggplot stats, brackets ---------------------- 

#stats on plots - brackets with asterisks 


```{r}
my_comparisons <- list(c("D", "F"), c("D", "G"), c("F", "J"))

ggplot(diamonds[1:500,], aes(color, depth)) +
  geom_violin(fill = NA, color = "grey", alpha = 0.5) +
  geom_jitter(width = 0.2, alpha = 0.5, size = 2,
              shape = 21, color = "black", aes(fill = color)) +
  scale_fill_ipsum() +
  theme_bw() +
  stat_compare_means(comparisons = my_comparisons, label.y = c(68, 69, 70), aes(label = ..p.signif..)) +
  stat_summary(fun.data=mean_se, fun.args = list(mult=1), 
               geom="errorbar", color="black", width=0.2) +
  stat_summary(fun.y=mean, geom="point", color="black")
```




```{r}
Housing %>% kruskal_test(price ~ stories)  # start w/ non-parametric ANOVA
```


# plot all (and only) significant differences

```{r}

D.ttest <- Housing %>% wilcox_test(price ~ stories, paired = FALSE, p.adjust.method = "BH") %>%   # tests all comparisons
  filter(p.adj < 0.05) %>%
  rstatix::add_significance("p") %>%
  rstatix::add_y_position() %>%
  mutate(y.position = seq(1.05*max(Housing$price), 1.05*max(Housing$price)*(1+0.07*n()), length.out = n()))

Housing %>% ggplot(., aes(x = factor(stories), y = price)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1, color = "#313E61", alpha = 0.5) +
  ggpubr::stat_pvalue_manual(D.ttest, label = "p.adj") 

```


compare all groups to one "ref.group"

```{r}
D.ttest <- Housing %>% wilcox_test(price ~ stories, paired = FALSE, p.adjust.method = "BH", ref.group = "1") %>%  # ref group restricts to tests against "1"
  filter(p.adj < 0.05) %>%
  rstatix::add_significance("p") %>%
  rstatix::add_y_position() %>%
  mutate(y.position = seq(1.05*max(Housing$price), 1.05*max(Housing$price)*(1+0.07*n()), length.out = n()))

Housing %>% ggplot(., aes(x = factor(stories), y = price)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1, color = "#313E61", alpha = 0.5) +
  ggpubr::stat_pvalue_manual(D.ttest, label = "p.adj") 
```
  

Specify comparisons manually

```{r}
compare.list <- list(c(1, 2), c(3, 4))

Housing %>% ggplot(., aes(x = factor(stories), y = price)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1, color = "#313E61", alpha = 0.5) +
  stat_compare_means(comparisons = compare.list, aes(label = ..p.signif..))
```

Kruskal-Wallis ANOVA

```{r}

Housing %>% ggplot(., aes(x = factor(stories), y = price)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = 0.1, color = "#313E61", alpha = 0.5) +
  stat_compare_means(method = "kruskal.test", label.y = max(Housing[["price"]])*1.1)+        # Add global anova p-value
  stat_compare_means(label = "p.signif", method = "wilcox.test",
                     ref.group = ".all.", hide.ns = TRUE)  
```




[  Section 9  ] ------------ Median Centering Data Libraries ---------------------- 

```{r}

setwd("C:/Users/kjwl754/Desktop")

# upload csv
df <- read_excel("raybio.xlsx")

quantile_normalisation <- function(df)  {
  
  # drop rownames column
  df = df[,-1]
  
  # determine ranks of each column
  # (indexes of values ascending)
  df_rank <- apply(df,2,rank,ties.method="min")
  
  # sort all columns in ascending order
  df_sort <- data.frame(apply(df, 2, sort))
  
  # calculate means of all columns
  df_mean <- apply(df_sort, 1, mean)
  
  index_to_mean <- function(my_index, my_mean){
    return(my_mean[my_index])
  }
  
  df_final <- apply(df_rank, 2, index_to_mean, my_mean=df_mean)
  rownames(df_final) <- rownames(df)
  return(df_final)
}

#Check result of median centering

p.preNorm <- mtcars %>% as_tibble(rownames = "Car_types") %>%                  #Pre-norm
  pivot_longer(-`Car_types`, names_to = "Variables", values_to = "quant_centered_obs") %>%
  ggplot(aes(Variables, quant_centered_obs)) +
  geom_boxplot(outlier.colour="red", outlier.shape=8,
                outlier.size=4)

df_norm = cbind(quantile_normalisation(mtcars), mtcars[,1])       #Run the normalization

p.postNorm <- df_norm %>% as_tibble(rownames = "Car_types") %>%                  #Post-norm
  pivot_longer(-`Car_types`, names_to = "Variables", values_to = "quant_centered_obs") %>%
  ggplot(aes(Variables, quant_centered_obs)) +
  geom_boxplot(outlier.colour="red", outlier.shape=8,
                outlier.size=4)

p.preNorm / p.postNorm

#write_xlsx(x = df_norm, path = "RayBio_Norm.xlsx", col_names = TRUE)


```











[  Section 10 ] ---------------   PURRR Examples - lists and iteration  -------------------------




Convert a list of vectors of unequal lengths to data frame in long format

```{r}

list(letters[1:10], letters[11:15]) %>%                     #create list of vectors
  set_names(c("first_vector", "second_vector")) %>%         #Name vectors
  vctrs::vec_cbind() %>%                                    #Stack vectors vertically                           
  set_names("Items") %>%                                    #Name new vector
  unnest(.id = "Type")                                      #Expand and name vector type

```



Convert list of vectors into one vector

```{r}

list.vects <- list(c(1,2,3),c(4,5,6))
list.vects

one.vect <- list.vects %>% flatten() %>% unlist()
one.vect
```



Create list of plots from nested data frame

```{r}

DF <- mtcars %>% group_by(cyl, carb) %>% nest()

df <- mtcars

testplot <- function(df)
{
p <- ggplot(df, aes(fill=mpg, y=disp, x = as.factor(wt)))
p + geom_bar(position="dodge", stat="identity") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
}

testplot(df)

p.list <- pmap(list(a = DF$data, b = DF$cyl, c = DF$carb), 
.f = function(a,b,c) testplot(a) + labs(title = b, subtitle = c))

p.list %>% marrangeGrob(., ncol = 3, nrow =2)
```

List of plots from split data frame

```{r}

mahnewlist <- Housing %>%
  split(., Housing$stories)

mahnewlist %>% map2(.x =., .y = names(.), ~ggplot(., aes(x = .data[["price"]], y = .data[["lotsize"]])) +
                      labs(title = paste0("Stories = ", .y)) +
                      geom_point(aes(color = airco)))

```



Join multiple data frames by multiple joining columns

```{r}
x <- tibble(A = seq(1,5, 0.5),
            B = seq(3,7, 0.5))

y <- tibble(A = seq(4, 9, 0.5),
            C = seq(1.5, 6.5, 0.5))

z <- tibble(C = seq(1, 6, 0.5),
            D = seq(2, 7, 0.5))

list_DFs_to_join <- append(list(x, y), z)   # OPTION 1
# OR
list_DFs_to_join <- list(x, y, z)           # OPTION 2

Reduce(function(x, y) intersect(x, y), list(names(x), names(y), names(z)))

(multi_full <- Reduce(                      # join all data frames together
  function(x, y)
    full_join(x, y, by = intersect(names(x), names(y))), list_DFs_to_join
))
```






[  Section 11 ] --------------------   Exploratory Analysis: Correlation & Violin  ---------------------------


Input data frame


```{r}
#DF <- sample_n(diamonds, 300)
DF <- book_words

   ##Explore correlations - numeric data

if ((DF %>% map_lgl(~is.numeric(.x)) %>% sum()) >= 2) {

DF %>%                  #corr plot method = 'arg' should be one of “circle”, “square”, “ellipse”, “number”, “shade”, “color”, “pie”
  select_if(is.numeric) %>% 
  cor(method = "spearman") %>% 
  corrplot(., type="lower", 
           method = "ellipse", 
           order="FPC", 
           tl.col="black", 
           tl.srt=45, 
           sig.level = 0.01, 
           insig = "blank", 
           diag=FALSE,
           col=brewer.pal(n=8, name="PuOr")) 
} else {
  
  print("no numeric correlations possible")
  
}

##Explore Violin plots - factor data

   #OPTION 1
#Create variable combos to plot against each other - by VARIABLE LEVELS < set amt
factors <- DF %>% map_dfr(., .f = ~ length(unique(.x)) < 15) %>% select_if(. == TRUE) %>% names()
non.factors <- setdiff(names(DF), factors)
plot.combos <- expand.grid(factors, non.factors)

   #OPTION 2
#Create variable combos to plot against each other - by CHARACTER VECTORS
chr.factors <- DF %>% select_if(negate(is.numeric)) %>%
  map_dfr(., .f = ~ length(unique(.x)) < 15) %>% select_if(. == TRUE) %>% names()
non.chr.factors <-  setdiff(names(DF), factors)
plot.combos <- expand.grid(chr.factors, non.chr.factors)

plot.combos

p.v <- map2(
  .x = plot.combos[,1], 
  .y = plot.combos[,2], 
  .f = ~ ggplot(DF, aes(x = DF[[.x]], y = as.numeric(DF[[.y]]), fill = DF[[.x]])) + 
       geom_violin() + 
       scale_fill_viridis_d(option = "magma") + 
       labs(x = as.character(.x), y = as.character(.y), fill = .x) +
       scale_y_continuous(trans = "log10") +
       theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1))
       )

length(p.v)

p.v   #View these as long as there aren't too many
```








[  Section 12 ] Principal Components Analysis (PCA)


# Tidymodels/recipe method for PCA & UMAP

```{r}

library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE,
                      message = FALSE, echo = TRUE, dpi = 180,
                      fig.width = 8, fig.height = 5)

library(tidyverse)
library(silgelib)
library(tidyverse)
library(tidymodels)
theme_set(theme_plex())

```

grab United Nations voting data

```{r}

unvotes <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-23/unvotes.csv")

issues <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-23/issues.csv")

unvotes

issues

```

Munging -> data frame showing country x rcid (voting instance)

```{r}

# Voting instances
unvotes$rcid %>% unique() %>% length()

unvotes_df <- unvotes %>%
  select(country, rcid, vote) %>%
  mutate(vote = factor(vote, levels = c("no", "abstain", "yes")),           # give numeric values in 2 steps
         vote = as.numeric(vote),
         rcid = paste0("rcid_", rcid)) %>%
  pivot_wider(names_from = "rcid", values_from = "vote", values_fill = 2)   # call empty values "abstention" (factor level = 2)

unvotes_df %>% class

```


# PCA

```{r}

unvotes_df %>% dim

pca_rec <- recipe(~., data = unvotes_df) %>%       # recipe for pre-processing data...inclued data to be trained
  update_role(country, new_role = "id") %>%        # specify that it's the countries that should be clustered
  step_normalize(all_predictors()) %>%             # same as scale...mean = 0, SD = 1
  step_pca(all_predictors())                       # PCA for all predictors

pca_prep <- prep(pca_rec)                          # train a data recipe

pca_prep

```

Plot the PCA results

```{r}

bake(pca_prep, new_data = NULL) %>%                # apply a trained data recipe, don't change the data
  ggplot(aes(PC1, PC2, label = country)) +         
  geom_point(color = "midnightblue", alpha = 0.7, size = 2) +
  geom_text(check_overlap = TRUE, hjust = "inward")

```

Which issues accounts for variation among countries

```{r}
pca_comps <- tidy(pca_prep, 2) %>%                      # tidy the output of a recipe
  filter(component %in% paste0("PC", 1:4)) %>%
  left_join(issues %>% mutate(terms = paste0("rcid_", rcid))) %>%
  filter(!is.na(issue)) %>%
  group_by(component) %>%             # select most important components of variation for each PC
  slice_max(abs(value), n = 8) %>%    
  ungroup()

pca_comps %>%        
  mutate(value = abs(value)) %>%
  ggplot(aes(value, terms, fill= issue)) +
  geom_col(position = "dodge") +
  facet_wrap(~component, scales = "free_y") +
  labs(y = NULL, fill = NULL,
       x = "Absolute value contribution")

```



# UMAP

```{r}

library(embed)

unvotes_df %>% dim

umap_rec <- recipe(~., data = unvotes_df) %>%
  update_role(country, new_role = "id") %>%
  step_normalize(all_predictors()) %>%         #same as scale() function... mean of 0 and 1 x SD = 1
  step_umap(all_predictors())

umap_prep <- prep(umap_rec)

umap_prep

```


```{r, fig.width = 10, fig.height = 5}

bake(umap_prep, new_data = NULL) %>%
  ggplot(aes(umap_1, umap_2, label = country)) +
  geom_point(aes(fill = ifelse(factor(country) %in% "China", "red", "midnightblue")), shape = 21, color = "black", alpha = 0.7, size = 2) +
  geom_text(check_overlap = TRUE, hjust = "inward") 

```








############# older method for PCA ##############


```{r, fig.width = 10, fig.height = 8}


#D.4.pca <- biopsy         # Add data frame here
D.4.pca <- D.expresMTX %>% 
ExpDate <- "000000"       # Add experiment date here

pca_fit <- D.4.pca %>% 
  select_if(is.numeric) %>% 
  scale() %>%
  t() %>%
  na.omit() %>%
  t() %>%
  prcomp(scale = TRUE) # do PCA on scaled data

(p.pca <- pca_fit %>%                                   # MAIN PCA PLOT
  augment(D.4.pca) %>%                                  # add original dataset back in
  ggplot(aes(.fittedPC1, .fittedPC2, color = class)) +  # Set coloring
  geom_point(size = 1.5, alpha = 0.8) +
  scale_color_manual(
    values = c(malignant = "#DB1F48", benign = "#01949A")
  ) + 
  labs(x = "PC1", y = "PC2", title = "PCA") +
  theme_half_open(12) + background_grid())

# define arrow style for plotting
arrow_style <- arrow(
  angle = 20, ends = "first", type = "closed", length = grid::unit(8, "pt")
)

(p.eigenvectors <- pca_fit[["rotation"]] %>%                          # EIGENVECTORS
  as_tibble(rownames = "V") %>%
  ggplot(aes(PC1, PC2)) +
  geom_segment(xend = 0, yend = 0, arrow = arrow_style) +
  #geom_text(
  #  aes(label = column),
  #  hjust = 1, nudge_x = -0.02, 
  #  color = "#004369"
  #) +
  geom_text_repel(aes(label = V), color = "#004369") +
  xlim(-1.25, .5) + ylim(-.5, 1) +
  labs(title = "Eigenvectors") +
  coord_fixed() + # fix aspect ratio to 1:1
  theme_minimal_grid(12))
  
(p.scree <- pca_fit %>%                                 # SCREE PLOT
  tidy(matrix = "pcs") %>%
  ggplot(aes(PC, percent)) +
  geom_col(fill = "#004369", alpha = 0.8) +
  scale_x_continuous(breaks = 1:9) +
  scale_y_continuous(
    labels = scales::percent_format(),
    expand = expansion(mult = c(0, 0.01))
  ) +
  labs(title = "Scree plot") +
  theme_minimal_hgrid(12))

p.combo <- (p.pca | p.eigenvectors) / (p.scree + plot_spacer()) & plot_annotation(title = paste0(ExpDate, " Principal components analysis"))
                                                                                  
p.combo

```

```{r}

ggsave(p.pca, filename = paste0(here(), "/", ExpDate, " PCA.tiff"), dpi = 300, width = 5, height = 4)
ggsave(p.eigenvectors, filename = paste0(here(), "/", ExpDate, " eigenvect.tiff"), dpi = 300, width = 5, height = 4)
ggsave(p.scree, filename = paste0(here(), "/", ExpDate, " scree.tiff"), dpi = 300, width = 5, height = 4)
ggsave(p.combo, filename = paste0(here(), "/", ExpDate, " PCA comboPlot.tiff"), dpi = 300, width = 12, height = 10)
```








[  Section 13 ] Color Strategies



Find schemes of 4 colors w HEX CODES
https://www.canva.com/colors/color-palettes/

Discrete color palettes

```{r}

# 4 colors // CANVA

canvaSCHEMES <- tibble(
  DiaphanousJellyfish = c("#041F60", "#0476D0", "#2CEEF0", "#B4F5F0"), 
  InTheBlue = c("#0C6980", "#00A8A8", "#2EB5E0", "#C4DBE0"),
  TwartedSummerShower = c("#4C5270", "#F652A0", "#36EEE0", "#BCECE0"),
  LusciousLemonade = c("#E1C340", "#4CD7D0", "#A4E8E0", "#F8EA8C"),
  BerryJar = c("#F83839", "#513B41", "#7FE5F0", "#C8F4F9"),
  BottleofMilk = c("#F4F7F0", "#BFD2D0", "#368980", "#62CCC0"),
  BoldGeometry = c("#E34234", "#050533", "#F2F1E8", "#0D698B"),
  ToweringOver = c("#FFD53D", "#40B0DF", "#0067B3", "#0000A3"),
  NorthernLights = c("#08313A", "#5CD85A", "#107869", "#1A5653"),
  CoffeeRun = c("#2F435A","#AB6B51", "#D0B49F", "#39918C"),
  ColorfulPowderCracks = c("#050833", "#00BEC5", "#FF0BAC", "#54086B"),
  FreshBlankets = c("#81ABBC", "#313E61", "#FBD2C9", "#774A62")
) %>% map(., ~ show_col(.x))


# 7 colors
okabe <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
okabe %>% show_col() 


#Specify no. of colors
nCol <- 25
myCol <- viridis(n = nCol) #generate hex codes
show_col(myCol)            #print hex

myCol <- viridis(n = nCol, option = "E")
show_col(myCol)

#Create continuous gradient

cols <- colorRampPalette(c("blue", "yellow", "red"))(100)
show_col(cols)

cols <- cubehelix(256)
show_col(cols)

library(jcolors)
display_all_jcolors()


```

Continuous color palettes

```{r}

display_all_jcolors_contin()

display.brewer.all()

#diverging_continuous


```






[  Section 14 ] --------------------   Export list of plots as .pdf or as .tiff's (and plot data str.)  ---------------------------

```{r}

                                     #Set parameters
ExportFolder <- "_newfolder"
ExportFileName <- "_exportfilename"
DF <- mtcars
ExpDate <- "000000"
setwd("C:/Users/kjwl754/Desktop")

p.num.discrete <- DF %>% select_if(function(col) is.numeric(col) && unique(col) > 6) %>% 
  map2(., names(.), ~ ggplot(mapping = aes(x = .x)) + 
         geom_histogram(aes(fill = ..count..), color = "black") + 
         labs(x =.y) +
         theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1)))

p.num.contin <- DF %>% select_if(function(col) is.numeric(col) && unique(col) <= 6) %>% 
  map2(., names(.), ~ ggplot(mapping = aes(x = as.factor(.x))) + 
         geom_histogram(stat="count", aes(fill = .x), alpha = .8, color = "black") +
         labs(x =.y) +
         scale_fill_viridis_c(option = "inferno") +
         theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1)))

p.factor <- DF %>% select_if(function(col) !is.numeric(col)) %>% 
  map2(., names(.), ~ ggplot(mapping = aes(x = as.factor(.x))) + 
         geom_histogram(stat="count", aes(fill = .x), alpha = .8, color = "black") +
         labs(x =.y) +
         scale_fill_viridis_d(option = "magma") +
         theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1)))

p.comboLIST <- c(p.factor, p.num.contin, p.num.discrete)            # Combine plots into list


      # EXPORT AS PDF
(p.export <- p.comboLIST %>% marrangeGrob(., ncol = 3, nrow = 2))   # Make pages to export

dir.create(paste0(ExpDate, "_", ExportFolder))                      # Create folder
ggsave(paste0(ExpDate, ".pdf"), p.export, path = here(paste0(ExportFolder)), height = 7, width = 11)  # send .pdf to folder

      # EXPORT AS TIFFs
filenames <- paste(ExpDate, names(DF), 1:length(p.comboLIST))       # make names for individual .tiff files
dir.create(paste0(ExportFolder))                                    # Create folder
walk2(.x = p.comboLIST, .y = filenames, .f = ~ ggsave(filename = paste0(.y, ".tiff"),    # Send .tiff files to dir
                                               path = here(paste0(ExportFolder)),
                                               plot = .x, height = 4, width = 5, dpi = 300))

```
















[  Section 16 ]  -----------------------------     Move & rename files     ------------------------------

```{r}

#LOX1proj.folder <- paste0("C:/Users/kjwl754/Desktop/", 
#                          substring(str_replace_all(Sys.Date(), "-", ""),3), 
#                          "_LOX1proj_backup" )

#dir.create(LOX1proj.folder)

orig_folder <- "C:/Users/kjwl754/Box Sync/Projects/LOX1"
dest_folder <- "LOX1proj.folder"

list_of_files <- list.files(orig_folder)   
#file.copy(file.path(orig_folder, list_of_files), dest_folder, recursive=TRUE)

list.files("C:/Users/kjwl754/Box Sync")[!list.files("C:/Users/kjwl754/Box Sync") %in% "Projects"]

```


Rename files

```{r}

getwd()
old <- list.files()
old

exts <- map(old, ~ strsplit(.x, "\\.") %>% flatten() %>% tail(., 1)) %>% unlist
exts

#new <- map2(old, exts, ~ str_extract(.x, "(\\d{6})") %>% paste0(.,".", .y))
new <- map2(old, exts, ~ str_extract(.x, "(\\d{6})"))
new

#Make sure new looks correct before running the following
# walk2(.x = old, .y = new, ~ file.copy(.x, .y, overwrite = FALSE))
# 
# 
# walk(new, ~ dir.create(.x))   # create new list of folders
# 
# length(old) == length(new)
# 
# walk2(.x = old, .y = new, ~ file.copy(.x, .y, recursive=TRUE, overwrite = FALSE))

```

















[  Section 17 ]  -----------------------   Rowwise calculations  -----------------------------






Simple row-wise calculation  __ rowwise()

```{r}

mtcars %>% 
  rowwise() %>%
  mutate(med = median(c(cyl, disp, hp)))

mtcars %>% 
  rowwise() %>%
  mutate(newcol = vs + am - gear)

# another way to calculate rowwise summary stats

df <- tibble(id = 1:4, w = runif(4), x = runif(4), y = runif(4), z = runif(4))
df %>%
  rowwise() %>%
  mutate(
    sum = sum(c_across(w:z)),
    sd = sd(c_across(w:z))
 )
```




Create a list of functions and apply rowwise  __  summarise() & across()

```{r}
#create a list of functions if >1 needed
median_and_max <- list(
  med = ~median(.x, na.rm = TRUE),
  max = ~max(.x, na.rm = TRUE)
)

# calculate rowwise stats using across() and pivot_longer
  
infert %>% summarise(across(is.numeric, median_and_max)) %>%   # generates summary stats
  pivot_longer(., cols = `age_med`:`pooled.stratum_max`,       # pivot longer and separate out var & function names into 2 cols
               names_to = c("var", "statistic"),
               names_sep = "_",
               values_to = "count"
               )
```



 
Substitute for mutate_at()

```{r}
iris %>%
  as_tibble() %>%
  mutate(dplyr::across(where(is.factor), as.character))

```



Mutate based on arbitrarily complex conditional
Case_when() function

```{r}
mydata <- c(1,2,3,4,5,6,7)                  # case_when() for vector

case_when(
  mydata%%2==0 ~ "even",
  mydata%%2==1 ~ "odd",
  TRUE ~ "neither even nor odd"
)


library(MASS)                               # case_when() for mutate of data frame
Housing %>% 
  select(price) %>% 
  mutate(newcol = 
           case_when(
             price < 50000 ~ "cheap",
             price >= 50000 ~ "expensive",
             TRUE ~ "neither"
           ))
```




Replace specific value in data frame

```{r}
iris %>% mutate(NewVar = replace(`Sepal.Length`, Sepal.Length < 5, "LESSthanfive"))
```




Replace specific values in existing vector

```{r}
(old.vec <- sample(c("a","b","c"), 10, replace = TRUE))    # original vector

(new.vec <- c("apple", "banana", "coconut"))     # replacement values in correct order

recode(old.vec, a = "apple", b = "banana")   # replace specific items in vector
```




Replace entire vector based on prior vector using a factor
(alternative is to create tibble key and left_join() )

```{r}
(old.vec <- sample(c("a","b","c"), 10, replace = TRUE))    # original vector

(new.vec <- c("apple", "banana", "coconut"))               # replacement values in correct order

factor(old.vec, labels = new.vec)            # replace one vector entirely with new vector 

tibble(                                      # check replacements match original
  old = old.vec,
  new = factor(old.vec, labels = new.vec)
)
```




Recode entire vector for data frame

```{r}

factor(mtcars$cyl)

lett <- LETTERS[1:3]      # replacement values in an order that matches the order of factor levels of mtcars$cyl

mtcars %>%
  mutate(newcyl = factor(cyl, labels = lett)) %>% View()

```









[  Section 18 ]  -----------------------   Text analysis  -----------------------------


Tidytext - clean up notes

```{r}

protests <- vroom("C:/Users/kjwl754/Desktop/mmALL_073120_csv.csv")   # google the file to find
protests %>% glimpse()

protest_words <- protests %>% 
  select(id, notes) %>% 
  unnest_tokens(output = word, input = notes)  # convert notes to long format

protest_words %>% count(word, sort = TRUE)

protest_words %>% anti_join(stop_words, by = "word") %>%   # remove filler words
  count(word, sort = TRUE)

```




[  Section 19  ]  ------------------------       qRT-PCR       -------------------------



Colnames for raw data come from a QuantStudio 12K and may need to change

```{r}


ExpDate <- "210329"

list.files()

DF <- read_excel("2021-04-19 mat neu scale up 1_20.xlsx", sheet = "Results", skip = 31)

DF2 <- DF %>% filter(!`Sample Name` %in% c("Analysis Type", "Endogenous Control", "RQ Min/Max Confidence Level", "Reference Sample" )) %>%
  mutate(ID_Tag = str_extract(.$`Sample Name`, "[0-9]+") %>% as.numeric) %>% select(ID_Tag, everything())

DF2 <- filter(DF2, !is.na(`Target Name`))    # remove the NT control

DF3 <- DF2 %>% 
  group_by(ID_Tag, `Target Name`) %>% 
  mutate(sample_num = n()) %>%
  ungroup() %>%
  arrange(ID_Tag) %>%
  mutate(Undet_count = ifelse(CT == "Undetermined", 1, 0)) %>%
  group_by(`Target Name`, `Sample Name`) %>%
  mutate(Undet_count = sum(Undet_count)) %>%
  mutate(replicates = n())

DF3 %>%
  ggplot(., aes(fct_reorder(`Sample Name`, `ID_Tag`, .desc = TRUE), y = `Target Name`)) +
  geom_point(aes(fill = `Target Name`, color = factor(`Undet_count`))) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) +
  coord_flip() +
  labs(x = "Samples", title = "Experiment Structure", color = "No. of non-detects")

DF1_20 <- DF3 %>% 
  group_by(ID_Tag) %>%
  filter(Undet_count == 0)

DF1_20 %>%
  ggplot(., aes(fct_reorder(`Sample Name`, `ID_Tag`, .desc = TRUE), y = `Target Name`)) +
  geom_point(aes(fill = `Target Name`, color = factor(`Undet_count`))) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) +
  coord_flip() +
  labs(x = "Samples", title = "Experiment Structure", color = "No. of non-detects")

```


```{r}

list.files()

DF <- read_excel("2021-04-19 mat neu 21_40-QuantStudio 12K Flex-export.xlsx", sheet = "Results", skip = 31)

DF2 <- DF %>% filter(!`Sample Name` %in% c("Analysis Type", "Endogenous Control", "RQ Min/Max Confidence Level", "Reference Sample" )) %>%
  mutate(ID_Tag = str_extract(.$`Sample Name`, "[0-9]+") %>% as.numeric) %>% select(ID_Tag, everything())

recode_ID_tags <- tibble(ID_Tag = 1:20,
                         ID_Tag_2 = 21:40)

DF2 <- filter(DF2, !is.na(`Target Name`)) 

DF3.b <- DF2 %>% 
  group_by(ID_Tag, `Target Name`) %>% 
  mutate(sample_num = n()) %>%
  ungroup() %>%
  arrange(ID_Tag) %>%
  mutate(Undet_count = ifelse(CT == "Undetermined", 1, 0)) %>%
  group_by(`Target Name`, `Sample Name`) %>%
  mutate(Undet_count = sum(Undet_count)) %>%
  mutate(replicates = n())

DF3.b %>%
  ggplot(., aes(fct_reorder(`Sample Name`, `ID_Tag`, .desc = TRUE), y = `Target Name`)) +
  geom_point(aes(fill = `Target Name`, color = factor(`Undet_count`))) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) +
  coord_flip() +
  labs(x = "Samples", title = "Experiment Structure", color = "No. of non-detects")


DF21_40 <- DF3.b %>% 
  inner_join(., recode_ID_tags, by = "ID_Tag") %>% 
  filter(!is.na(ID_Tag_2)) %>%
  select(-ID_Tag) %>%
  rename(ID_Tag = ID_Tag_2) %>%
  group_by(ID_Tag) %>%
  filter(Undet_count == 0)

DF21_40 %>%
  ggplot(., aes(fct_reorder(`Sample Name`, `ID_Tag`, .desc = TRUE), y = `Target Name`)) +
  geom_point(aes(fill = `Target Name`, color = factor(`Undet_count`))) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1)) +
  coord_flip() +
  labs(x = "Samples", title = "Experiment Structure", color = "No. of non-detects")

```




```{r}

D.1_40 <- bind_rows(DF1_20, DF21_40) %>%
  select(ID_Tag, `Target Name`, `EQ.Ct Mean`) %>% distinct()

D.1_40 %>% ggplot(., aes(factor(ID_Tag), `Target Name`)) +
  geom_point()

```




```{r}
metadata.filename <- paste0("ab", ExpDate, " Assay.xlsx")

D.meta <- read_excel(metadata.filename, sheet = "Conditions")
D.j <- inner_join(D.meta, D.1_40, by = "ID_Tag")
D.meta

D.wide <- D.j %>% 
  pivot_wider(., id_cols = `ID_Tag`, names_from = "Target Name", values_from = "EQ.Ct Mean") %>%
  mutate(delta_ct_arg = `ARG1`/`GAPDH`) %>%
  mutate(delta_ct_ptg = `PTGES`/`GAPDH`) %>%
  mutate(delta_ct_nos = `NOS2`/`GAPDH`) %>%
  inner_join(D.meta, ., by = "ID_Tag") %>%
  nest(-`Donor ID`) %>% 
  mutate(Donor_ref_arg = map(.$data, ~ .x %>% filter(Condition == "Unstim") %>% select(`delta_ct_arg`) %>% deframe)) %>% 
  unnest(data, Donor_ref_arg) %>% 
  mutate(ddCT_ARG = `delta_ct_arg`/`Donor_ref_arg`) %>%  
  nest(-`Donor ID`) %>% 
  mutate(Donor_ref_ptg = map(.$data, ~ .x %>% filter(Condition == "Unstim") %>% select(`delta_ct_ptg`) %>% deframe)) %>% 
  unnest(data, Donor_ref_ptg) %>% 
  mutate(ddCT_PTG = `delta_ct_ptg`/`Donor_ref_ptg`) %>% 
  nest(-`Donor ID`) %>% 
  mutate(Donor_ref_nos = map(.$data, ~ .x %>% filter(Condition == "Unstim") %>% select(`delta_ct_nos`) %>% deframe)) %>% 
  unnest(data, Donor_ref_nos) %>% 
  mutate(ddCT_NOS = `delta_ct_nos`/`Donor_ref_nos`)

D.wide <- D.wide %>% mutate(across(is.character, toGreek))
names(D.wide) <- as.list(names(D.wide)) %>% map_chr(., ~ toGreekLiteral(.x))
```


```{r}
D.wide %>% names()

D.wide %>% str()

p.arg.mRNA <- D.wide %>%
  ggplot(., aes(fct_reorder(Condition, `bar_sorting_var`), ddCT_ARG)) +
  #geom_hline(yintercept = 1, color = "red", size = 1) +
  geom_bar(stat = "summary", fun = "mean", alpha = 0.5, color = "black", aes(fill = factor(`Neutralization`))) + 
  geom_jitter(width = 0.2, color = "black", alpha = 0.5, aes(shape = factor(`Donor ID`))) + 
  #geom_text_repel(aes(label = `ID_Tag`)) +
  #facet_wrap(~.x, scales = "free") +
  theme(strip.background = element_rect(color="white", fill="#FFFFFF", size=0), 
        strip.text = element_text(colour = 'black', size = 12, face = "bold", hjust = 0),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.subtitle = element_text(color = "ivory", hjust = 1, size = 8),
        plot.margin = unit(c(0.2, 0.2, 0.2 ,0.5), "in")) +                                             
  stat_summary(position = position_dodge(width = 0.9), fun.data=mean_se, fun.args = list(mult=1),
        geom="errorbar", color="black", width=0.2, size = 0.5) +
  stat_summary(position = position_dodge(width = 0.9), fun="mean", geom="point", color="black") +
  scale_fill_ipsum() +
  scale_y_continuous(limits = c(0,2)) +
  labs(title = "ARG1 qPCR of mature o/n tx neutrophils",
       y = "ARG1 ddCt\nFold upreg. over Unstim.", 
       x = NULL, 
       fill = "Neutralization", 
       shape = "Donor", 
       caption = ExpDate)

p.arg.mRNA

PlotName <- "mRNA for ARG1"

ggsave(paste0("ab", ExpDate, "_", PlotName, ".tiff"), p.arg.mRNA, height = 5, width = 7, dpi = 300)

```

























 
 # # # # # # # # #                                              # # # # # # # # # 
###################           >  Install Packages  <           ####################
 # # # # # # # # #                                              # # # # # # # # # 



```{r}

if (!requireNamespace("BiocManager", quietly = TRUE))
  install.packages("BiocManager")
BiocManager::install()
library(BiocManager)
BiocManager::install("FlowSOM")
BiocManager::install("flowCore")
BiocManager::install("monocle")
BiocManager::install('EnhancedVolcano')
BiocManager::install('multtest')

install.packages("devtools")
library(devtools)
devtools::install("kassambara/ggpubr")
devtools::install("kassambara/rstatix")
devtools::install_github("JinmiaoChenLab/Rphenograph")
devtools::install_github('satijalab/seurat-data', force = TRUE)

install.packages("ape")
install.packages("colormap")
install.packages("corrplot")
install.packages("datasets")
install.packages("downloader")
install.packages("e1071")
install.packages("Ecdat")
install.packages("embed")
install.packages("epiR")
install.packages("esquisse")
install.packages("export")
install.packages("extrafont")
install.packages("extrafontdb")
install.packages("factoextra")
install.packages("FactoMineR")
install.packages("flexdashboard")
install.packages("gapminder") 
install.packages("ggbiplot")
install.packages("ggforce")
install.packages("ggfortify")
install.packages("ggpointdensity")
install.packages("ggpubr")
install.packages("ggrepel")
install.packages("ggridges")
install.packages("ggsave")
install.packages("ggsci")
install.packages("ggstatsplot")
install.packages("ggthemes")
install.packages("ggvis")
install.packages("ggh4x")
install.packages("glue")
install.packages("gmodels")
install.packages("gridBase")
install.packages("gridExtra")
install.packages("gtable")
install.packages("gtools")
install.packages("heatmaply")
install.packages("here")
install.packages("hflights")
install.packages("Hmisc")
install.packages("hms")
install.packages("https://seurat.nygenome.org/src/contrib/ifnb.SeuratData_3.0.0.tar.gz", repos = NULL, type = "source") 
install.packages("installr")
install.packages("janitor")
install.packages("jcolors")
install.packages("knitr")
install.packages("Lahman")
install.packages("magrittr")
install.packages("mlbench")
install.packages("nycflights13") 
install.packages("patchwork")
install.packages("pheatmap")
install.packages("plyr")
install.packages("pwr")
install.packages("pzfx")
install.packages("rafalib")
install.packages("RColorBrewer")
install.packages("readxl")
install.packages("remotes")
install.packages("repurrrsive")
install.packages("reshape")
install.packages("reshape2")
install.packages("RPostgreSQL")
install.packages("Rtools")
install.packages("rstatix")
install.packages("scales")
install.packages("sciplot")
install.packages("scclusteval")
install.packages("stringr")
install.packages("tidylog")
install.packages("tidyr")
install.packages("tidytext")
install.packages("tidyverse")
install.packages("tm")
install.packages("tsibble")
install.packages("ursa")
install.packages("VennDiagram")
install.packages("viridis")
install.packages("vroom")
install.packages("wordcloud")
install.packages("writexl")
install.packages("xlsx")
install.packages('ape')
install.packages('Impute')
install.packages('lubridate')
install.packages('metap')
install.packages('rsvd')
install.packages('Seurat')
install.packages('tidyverse')
install.packages("tidymodels")
install_github("vqv/ggbiplot")
InstallData("ifnb")
InstallData("panc8")
devtools::install_github("crazyhottommy/scclusteval")
remotes::install_github("juliasilge/silgelib")

remotes::install_bitbucket("hrbrmstr/hrbrthemes")
remotes::install_github("satijalab/seurat-data", force = TRUE)
#installr::uninstall.packages("Seurat")

```





